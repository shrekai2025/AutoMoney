# 数据流与调度机制

> 版本: 2.0  
> 更新日期: 2025-11-05  
> 目标: 解释数据如何采集、处理、流转以及任务如何调度

---

## 一、数据流总览

### 1.1 数据流向图

```
外部数据源
  ↓
[数据采集层] (每小时/每日)
  ├─ Binance API → 价格数据
  ├─ Glassnode API → 链上数据  
  ├─ FRED API → 宏观数据
  └─ Alternative.me → 情绪指数
  ↓
[数据处理层]
  ├─ 清洗: 去重、填充缺失值
  ├─ 计算: EMA、RSI等技术指标
  └─ 存储: Redis缓存 + PostgreSQL持久化
  ↓
[策略调度器] (APScheduler)
  ├─ 4小时策略触发
  ├─ 10分钟策略触发
  └─ 用户对话触发
  ↓
[Agent执行层]
  ├─ 从Redis读取最新数据
  ├─ LangGraph工作流执行
  └─ LLM API调用
  ↓
[决策执行层]
  ├─ 生成交易信号
  ├─ 模拟订单执行
  └─ 更新投资组合
  ↓
[WebSocket推送]
  └─ 实时通知前端
```

---

## 二、数据采集层设计

### 2.1 数据源配置表

| 数据源 | API | 频率 | 优先级 | 成本 | 失败策略 |
|-------|-----|------|--------|------|---------|
| **Binance** | REST | 5分钟 | P0 | 免费 | 降级到CoinGecko |
| **Glassnode** | REST | 1小时 | P0 | $29/月 | 使用缓存 |
| **FRED** | REST | 1天 | P1 | 免费 | 使用缓存 |
| **Alternative.me** | REST | 1小时 | P1 | 免费 | 使用默认值50 |

### 2.2 数据采集器设计

#### 2.2.1 通用采集器接口

```python
class DataCollector(ABC):
    @abstractmethod
    async def collect(self) -> dict:
        """采集数据"""
        pass
    
    @abstractmethod
    async def validate(self, data: dict) -> bool:
        """验证数据有效性"""
        pass
    
    @abstractmethod
    async def cache(self, data: dict):
        """缓存到Redis"""
        pass
```

#### 2.2.2 Binance价格采集器

**职责**: 获取BTC/ETH实时价格和K线数据

**采集周期**: 5分钟（与交易所限流匹配）

**数据格式**:
```python
{
    "symbol": "BTC",
    "price": 45000.00,
    "timestamp": "2025-11-05T12:00:00Z",
    "ohlcv": {
        "1h": [...],  # 最近100根1小时K线
        "4h": [...],  # 最近100根4小时K线
        "1d": [...]   # 最近100根日K线
    }
}
```

**错误处理**:
- API限流(429): 等待60秒后重试
- 超时: 3次重试，间隔2秒
- 彻底失败: 降级到CoinGecko API

#### 2.2.3 Glassnode链上数据采集器

**职责**: 获取MVRV、NVT、交易所流量等指标

**采集周期**: 1小时（数据更新频率限制）

**Starter计划限制**:
- 10 API calls/minute
- 历史数据: 最近1年

**数据缓存策略**:
- Redis TTL: 1小时
- PostgreSQL: 永久存储（每日快照）

**关键指标优先级**:
1. MVRV Z-Score (P0)
2. NVT Ratio (P0)
3. 交易所净流量 (P0)
4. 长期持有者变化 (P1)
5. 活跃地址数 (P2)

#### 2.2.4 FRED宏观数据采集器

**职责**: 获取美联储利率、M2货币供应等

**采集周期**: 每日凌晨3点（数据日更新）

**数据特点**:
- 更新频率低（月度/季度）
- 历史数据稳定
- 免费且稳定

**缓存策略**:
- Redis TTL: 24小时
- PostgreSQL: 按月存储

---

## 三、数据处理层设计

### 3.1 数据清洗规则

#### 3.1.1 缺失值处理

| 数据类型 | 缺失处理策略 | 理由 |
|---------|-------------|------|
| **价格数据** | 前向填充 | 使用上一个有效价格 |
| **链上数据** | 线性插值 | 变化缓慢，插值合理 |
| **宏观数据** | 使用上期值 | 月度数据，变化慢 |
| **情绪指数** | 默认50(中性) | 缺失时假设中性 |

#### 3.1.2 异常值检测

**价格数据异常规则**:
```python
def detect_price_anomaly(price, prev_price):
    # 单次涨跌超过20%视为异常
    change_pct = abs(price - prev_price) / prev_price
    if change_pct > 0.20:
        return "ANOMALY"
    return "NORMAL"
```

**处理策略**:
- 发现异常: 记录到日志
- 保留数据: 不删除（可能是真实暴涨暴跌）
- 标记字段: 添加`is_anomaly=True`标记

### 3.2 技术指标计算

#### 3.2.1 指标计算器架构

**使用库**: TA-Lib (专业技术指标库)

**计算周期**: 每5分钟（价格数据更新后）

**指标列表**:
| 指标 | 计算方法 | 输入周期 | 输出 |
|-----|---------|---------|------|
| EMA21 | 指数移动平均 | 周线 | 单一值 |
| EMA55 | 指数移动平均 | 周线 | 单一值 |
| RSI(14) | 相对强弱指数 | 周线 | 单一值 |
| MACD | 异同移动平均 | 周线 | 3个值 |
| Bollinger Bands | 布林带 | 周线 | 3个值 |
| ATR | 平均真实波幅 | 周线 | 单一值 |

#### 3.2.2 计算优化策略

**增量计算**:
- 不重新计算所有历史数据
- 仅计算新增K线对指标的影响
- 缓存中间结果

**示例** (EMA增量):
```python
def update_ema(prev_ema, new_price, period):
    multiplier = 2 / (period + 1)
    new_ema = (new_price - prev_ema) * multiplier + prev_ema
    return new_ema
```

### 3.3 数据存储策略

#### 3.3.1 Redis缓存策略

**缓存结构**:
```
market:data:BTC:latest → {price, timestamp, indicators}
market:data:BTC:kline:1h → List[OHLCV]
agent:score:macro:latest → {score, reasoning, timestamp}
```

**TTL设置**:
- 最新价格: 10秒
- K线数据: 1小时
- Agent Score: 4小时
- 宏观数据: 24小时

#### 3.3.2 PostgreSQL存储策略

**存储内容**:
- 每日K线快照（用于回测）
- Agent执行历史（永久）
- 策略决策记录（永久）
- 交易记录（永久）

**不存储**:
- 分钟级K线（太多，仅Redis）
- 临时计算结果

---

## 四、任务调度系统设计

### 4.1 APScheduler架构

#### 4.1.1 调度器配置

**调度器类型**: AsyncIOScheduler（异步）

**任务存储**: RedisJobStore（持久化）

**执行器**: AsyncIOExecutor（异步执行）

**配置示例**:
```python
scheduler = AsyncIOScheduler(
    jobstores={
        'default': RedisJobStore(
            host='redis',
            port=6379,
            db=0
        )
    },
    executors={
        'default': AsyncIOExecutor()
    },
    job_defaults={
        'coalesce': True,  # 合并错过的执行
        'max_instances': 1  # 同一任务不并发
    }
)
```

### 4.2 任务分类与周期

#### 4.2.1 数据采集任务

| 任务名 | 周期 | Cron表达式 | 优先级 |
|-------|------|-----------|--------|
| 采集Binance价格 | 5分钟 | `*/5 * * * *` | P0 |
| 采集Glassnode | 1小时 | `0 * * * *` | P0 |
| 采集FRED | 每日3点 | `0 3 * * *` | P1 |
| 采集Fear&Greed | 1小时 | `0 * * * *` | P1 |

#### 4.2.2 策略执行任务

| 策略 | 周期 | Cron表达式 | 说明 |
|-----|------|-----------|------|
| HODL-Wave | 4小时 | `0 */4 * * *` | 宏观波段策略 |
| High-Freq | 10分钟 | `*/10 * * * *` | 高频策略（未来） |

#### 4.2.3 维护任务

| 任务 | 周期 | 说明 |
|-----|------|------|
| 清理过期缓存 | 每日2点 | 删除Redis过期数据 |
| 数据库备份 | 每日4点 | 备份PostgreSQL |
| 性能指标统计 | 每小时 | 统计LLM成本、API调用次数 |

### 4.3 任务执行流程

#### 4.3.1 策略任务执行流程

```
[调度器触发]
  ↓
[检查前置条件]
  ├─ 数据是否最新？
  ├─ Agent是否就绪？
  └─ 上次执行是否完成？
  ↓
[创建任务上下文]
  ├─ strategy_id
  ├─ user_id (多用户场景)
  └─ execution_id
  ↓
[数据准备]
  ├─ 从Redis读取最新数据
  ├─ 验证数据完整性
  └─ 填充缺失值
  ↓
[LangGraph工作流执行]
  ├─ 并行执行3个Agent
  ├─ 决策层计算
  └─ 生成交易信号
  ↓
[结果处理]
  ├─ 保存到PostgreSQL
  ├─ WebSocket推送前端
  └─ 记录日志
  ↓
[清理]
  └─ 释放资源
```

#### 4.3.2 错误处理策略

**任务执行失败**:
1. **轻微错误**（单个Agent失败）: 
   - 记录日志
   - 使用降级结果
   - 继续执行
   
2. **严重错误**（数据缺失）:
   - 中止本次执行
   - 发送告警
   - 等待下次调度

3. **致命错误**（LLM API全部失败）:
   - 中止任务
   - 发送紧急告警
   - 暂停策略自动执行

**重试策略**:
```python
@scheduler.scheduled_job('interval', hours=4, 
                        max_instances=1, 
                        misfire_grace_time=600)
async def execute_strategy():
    retries = 3
    for attempt in range(retries):
        try:
            await run_strategy()
            break
        except RecoverableError as e:
            if attempt < retries - 1:
                await asyncio.sleep(60)  # 等待1分钟
                continue
            else:
                # 最后一次重试失败
                await notify_admin(e)
```

---

## 五、实时通信机制

### 5.1 WebSocket设计

#### 5.1.1 连接管理

**连接池**: 
- 每个用户最多3个连接
- 超时时间: 5分钟无活动断开
- 心跳检测: 每30秒ping一次

**认证**:
```python
# 客户端连接时携带JWT
socket = io('ws://api.automoney.app', {
    auth: {
        token: 'Bearer eyJhbGci...'
    }
})

# 服务端验证
@socketio.on('connect')
async def handle_connect(auth):
    token = auth.get('token')
    user = await verify_jwt(token)
    # 将连接加入用户的room
    socketio.join_room(f'user_{user.id}')
```

#### 5.1.2 事件类型

| 事件名 | 触发时机 | Payload | 频率 |
|-------|---------|---------|------|
| `agent:scores` | Agent分析完成 | {macro, onchain, ta scores} | 每4小时 |
| `decision:made` | 生成交易信号 | {signal, conviction, reasoning} | 每4小时 |
| `trade:executed` | 模拟交易执行 | {asset, action, price, quantity} | 不定 |
| `portfolio:update` | 投资组合变化 | {totalValue, pnl, holdings} | 交易后 |

#### 5.1.3 订阅机制

**客户端订阅**:
```typescript
// 订阅Agent Score更新
socket.emit('subscribe:agent_scores', { strategyId: 'hodl-wave' })

// 接收更新
socket.on('agent:scores', (data) => {
  console.log('New scores:', data)
})

// 取消订阅
socket.emit('unsubscribe:agent_scores')
```

**服务端发送**:
```python
# 策略执行完成后推送
async def broadcast_agent_scores(user_id, scores):
    await socketio.emit(
        'agent:scores',
        scores,
        room=f'user_{user_id}'
    )
```

### 5.2 降级策略

**WebSocket不可用时**:
1. 客户端自动降级到HTTP轮询
2. 每15秒轮询一次`/api/agents/scores`
3. 用户体验略差但可用

---

## 六、数据一致性保证

### 6.1 缓存与数据库一致性

**更新策略**: Write-Through（写穿）

```
写入流程：
数据更新 → Redis缓存 → PostgreSQL持久化

读取流程：
查询 → 先查Redis → 未命中查PostgreSQL → 写回Redis
```

**一致性保证**:
- Redis作为临时缓存，PostgreSQL为真实数据源
- 缓存失效后自动从数据库重建
- 关键数据（交易记录）先写数据库再写缓存

### 6.2 分布式锁

**使用场景**: 防止同一策略重复执行

```python
async def execute_strategy_with_lock(strategy_id):
    lock_key = f'lock:strategy:{strategy_id}'
    
    # 尝试获取锁
    if not await redis.set(lock_key, '1', nx=True, ex=3600):
        logger.info(f'{strategy_id} is already running')
        return
    
    try:
        await run_strategy(strategy_id)
    finally:
        # 释放锁
        await redis.delete(lock_key)
```

---

## 七、性能监控

### 7.1 关键指标

| 指标 | 目标 | 监控方式 |
|-----|------|---------|
| 数据采集成功率 | >99% | Prometheus |
| Agent执行时间 | <10s | 应用日志 |
| WebSocket延迟 | <100ms | 客户端上报 |
| Redis命中率 | >80% | Redis INFO |
| PostgreSQL慢查询 | 0条 | pg_stat_statements |

### 7.2 告警规则

| 告警 | 触发条件 | 级别 | 通知方式 |
|-----|---------|------|---------|
| 数据采集失败 | 连续3次失败 | 🟡 警告 | Slack |
| LLM API故障 | 连续5次失败 | 🔴 严重 | 电话+Slack |
| 策略执行延迟 | 超过20秒 | 🟡 警告 | Slack |
| Redis连接失败 | 无法连接 | 🔴 严重 | 电话 |

---

## 八、扩展性设计

### 8.1 水平扩展路径

**当前架构** (<100用户):
```
单机FastAPI进程
  ├─ HTTP Server
  ├─ APScheduler
  └─ WebSocket Server
```

**扩展后架构** (>500用户):
```
Load Balancer
  ├─ FastAPI Instance 1 (HTTP only)
  ├─ FastAPI Instance 2 (HTTP only)
  ├─ Celery Worker 1 (任务执行)
  ├─ Celery Worker 2 (任务执行)
  └─ WebSocket Server (独立)
```

### 8.2 数据库扩展

**读写分离** (>1000用户):
- Master: 写入
- Replica: 只读查询
- Redis缓存减轻读压力

**分库分表** (>10000用户):
- 按用户ID hash分表
- 时序数据按时间分区

---

## 九、故障演练

### 9.1 场景1: Glassnode API故障

**影响**: OnChainAgent无法获取数据

**应对**:
1. 使用Redis缓存的上次数据
2. 标记为降级状态
3. 降低OnChainAgent权重（40% → 20%）
4. 其他Agent权重补偿（Macro 40% → 50%）

### 9.2 场景2: Redis宕机

**影响**: 缓存失效，数据库压力增大

**应对**:
1. 自动降级到直接查询PostgreSQL
2. 限流API请求（60/min → 30/min）
3. 优先保证核心功能（策略执行）

### 9.3 场景3: 所有LLM API故障

**影响**: Agent无法执行

**应对**:
1. 暂停所有自动策略执行
2. 使用缓存的上次Agent Score
3. 发送紧急告警
4. 等待API恢复或人工介入

---

**📌 关键Takeaway**: 
- 数据采集与策略执行分离
- APScheduler管理所有定时任务
- Redis+PostgreSQL保证数据一致性
- WebSocket实现实时推送

**下一步**: 阅读 `04-数据库设计方案.md` 了解数据存储细节


