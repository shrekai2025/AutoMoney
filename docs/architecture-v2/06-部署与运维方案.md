# éƒ¨ç½²ä¸è¿ç»´æ–¹æ¡ˆ

> ç‰ˆæœ¬: 2.0  
> æ›´æ–°æ—¥æœŸ: 2025-11-05  
> ç›®æ ‡: è¯¦ç»†çš„éƒ¨ç½²æµç¨‹ã€è¿ç»´ç­–ç•¥å’Œç›‘æ§æ–¹æ¡ˆ

---

## ä¸€ã€éƒ¨ç½²æ¶æ„æ€»è§ˆ

### 1.1 éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | é€‚ç”¨åœºæ™¯ | æœˆæˆæœ¬ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|-----|---------|--------|------|------|
| **Railway (æ¨è)** | 0-500ç”¨æˆ· | $20-100 | é›¶è¿ç»´ã€è‡ªåŠ¨æ‰©å±• | æˆæœ¬ç•¥é«˜ |
| **Vercel+Railway** | 0-500ç”¨æˆ· | $20-100 | å‰ç«¯å…è´¹ã€ç®€å• | åˆ†ç¦»éƒ¨ç½² |
| **Docker Composeæœ¬åœ°** | å¼€å‘æµ‹è¯• | $0 | å®Œå…¨æ§åˆ¶ | éœ€æ‰‹åŠ¨ç®¡ç† |
| **AWSè‡ªå»º** | >500ç”¨æˆ· | $200+ | æ€§ä»·æ¯”é«˜ã€çµæ´» | éœ€DevOps |

**åˆæœŸæ¨è**: Vercel(å‰ç«¯) + Railway(åç«¯+æ•°æ®åº“)

---

## äºŒã€æœ¬åœ°å¼€å‘ç¯å¢ƒ

### 2.1 Docker Composeé…ç½®

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  # PostgreSQLæ•°æ®åº“
  postgres:
    image: timescale/timescaledb:latest-pg16
    container_name: automoney-postgres
    environment:
      POSTGRES_USER: automoney
      POSTGRES_PASSWORD: dev_password_123
      POSTGRES_DB: automoney_dev
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U automoney"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: automoney-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # åç«¯API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: automoney-backend
    environment:
      DATABASE_URL: postgresql://automoney:dev_password_123@postgres:5432/automoney_dev
      REDIS_URL: redis://redis:6379/0
      CLAUDE_API_KEY: ${CLAUDE_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JWT_SECRET: ${JWT_SECRET}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # å‰ç«¯
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: automoney-frontend
    environment:
      VITE_API_URL: http://localhost:8000
      VITE_WS_URL: ws://localhost:8000
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev -- --host

volumes:
  postgres_data:
  redis_data:
```

### 2.2 åç«¯Dockerfile

**backend/Dockerfile**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**backend/requirements.txt**:
```txt
# Webæ¡†æ¶
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-socketio==5.11.0
python-multipart==0.0.6

# æ•°æ®åº“
sqlalchemy==2.0.25
alembic==1.13.1
psycopg2-binary==2.9.9
asyncpg==0.29.0

# ç¼“å­˜
redis==5.0.1
hiredis==2.3.2

# è®¤è¯
pyjwt==2.8.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
google-auth==2.27.0

# LLM/Agent
langchain==0.1.4
langgraph==0.0.20
anthropic==0.15.0
openai==1.12.0

# æ•°æ®å¤„ç†
pandas==2.1.4
numpy==1.26.3
ta-lib==0.4.28
httpx==0.26.0

# ä»»åŠ¡è°ƒåº¦
apscheduler==3.10.4

# å·¥å…·
pydantic==2.5.3
pydantic-settings==2.1.0
python-dotenv==1.0.0
loguru==0.7.2

# æµ‹è¯•
pytest==7.4.4
pytest-asyncio==0.23.3
pytest-cov==4.1.0
```

### 2.3 å‰ç«¯Dockerfile

**frontend/Dockerfile.dev** (å¼€å‘):
```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 5173

CMD ["npm", "run", "dev", "--", "--host"]
```

**frontend/Dockerfile** (ç”Ÿäº§):
```dockerfile
FROM node:20-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# NginxæœåŠ¡
FROM nginx:alpine

COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 2.4 å¯åŠ¨è„šæœ¬

**scripts/dev-start.sh**:
```bash
#!/bin/bash

# æ£€æŸ¥.envæ–‡ä»¶
if [ ! -f .env ]; then
    echo "âŒ .envæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å¤åˆ¶.env.exampleå¹¶é…ç½®"
    exit 1
fi

# å¯åŠ¨Docker Compose
echo "ğŸš€ å¯åŠ¨å¼€å‘ç¯å¢ƒ..."
docker-compose up -d

# ç­‰å¾…æ•°æ®åº“å°±ç»ª
echo "â³ ç­‰å¾…æ•°æ®åº“å¯åŠ¨..."
sleep 5

# è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ“Š æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec backend alembic upgrade head

# æ˜¾ç¤ºæ—¥å¿—
echo "âœ… å¼€å‘ç¯å¢ƒå¯åŠ¨å®Œæˆï¼"
echo ""
echo "ğŸ“ æœåŠ¡åœ°å€:"
echo "   å‰ç«¯: http://localhost:5173"
echo "   åç«¯API: http://localhost:8000"
echo "   APIæ–‡æ¡£: http://localhost:8000/docs"
echo ""
echo "ğŸ“ æŸ¥çœ‹æ—¥å¿—: docker-compose logs -f"
```

---

## ä¸‰ã€Railwayéƒ¨ç½²ï¼ˆæ¨èæ–¹æ¡ˆï¼‰

### 3.1 ä¸ºä»€ä¹ˆé€‰Railwayï¼Ÿ

**ä¼˜åŠ¿**:
- âœ… **é›¶è¿ç»´**: æ— éœ€ç®¡ç†æœåŠ¡å™¨
- âœ… **è‡ªåŠ¨æ‰©å±•**: æ ¹æ®æµé‡è‡ªåŠ¨è°ƒæ•´
- âœ… **å†…ç½®æ•°æ®åº“**: PostgreSQL + Redisä¸€é”®åˆ›å»º
- âœ… **GitHubé›†æˆ**: æ¨é€ä»£ç è‡ªåŠ¨éƒ¨ç½²
- âœ… **åˆç†ä»·æ ¼**: $20èµ·æ­¥ï¼ŒæŒ‰éœ€ä»˜è´¹

**é™åˆ¶**:
- âš ï¸ å†·å¯åŠ¨æ—¶é—´: 2-5ç§’ï¼ˆå¯æ¥å—ï¼‰
- âš ï¸ æˆæœ¬ä¸Šé™: >500ç”¨æˆ·æ—¶è€ƒè™‘è‡ªå»º

### 3.2 Railwayéƒ¨ç½²æ­¥éª¤

#### Step 1: åˆ›å»ºé¡¹ç›®

```bash
# å®‰è£…Railway CLI
npm i -g @railway/cli

# ç™»å½•
railway login

# åˆå§‹åŒ–é¡¹ç›®
railway init
```

#### Step 2: é…ç½®æ•°æ®åº“

åœ¨Railway Dashboard:
1. ç‚¹å‡» **New** â†’ **Database** â†’ **PostgreSQL**
2. ç‚¹å‡» **New** â†’ **Database** â†’ **Redis**
3. è·å–è¿æ¥å­—ç¬¦ä¸²

#### Step 3: é…ç½®ç¯å¢ƒå˜é‡

åœ¨Railwayé¡¹ç›®è®¾ç½®ä¸­æ·»åŠ ï¼š

```
# æ•°æ®åº“ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
DATABASE_URL=postgresql://...
REDIS_URL=redis://...

# LLM API
CLAUDE_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...

# JWT
JWT_SECRET=your-super-secret-key-here
JWT_ALGORITHM=HS256

# Google OAuth
GOOGLE_CLIENT_ID=...
GOOGLE_CLIENT_SECRET=...

# æ•°æ®æºAPI
GLASSNODE_API_KEY=...
BINANCE_API_KEY=...

# ç¯å¢ƒ
ENVIRONMENT=production
LOG_LEVEL=INFO
```

#### Step 4: é…ç½®railway.json

**railway.json**:
```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "DOCKERFILE",
    "dockerfilePath": "backend/Dockerfile"
  },
  "deploy": {
    "startCommand": "uvicorn app.main:app --host 0.0.0.0 --port $PORT",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 3
  }
}
```

#### Step 5: éƒ¨ç½²

```bash
# è¿æ¥åˆ°Railwayé¡¹ç›®
railway link

# éƒ¨ç½²åç«¯
railway up

# æŸ¥çœ‹æ—¥å¿—
railway logs
```

### 3.3 è‡ªåŠ¨éƒ¨ç½²é…ç½®

**é…ç½®GitHub Actions** (.github/workflows/deploy.yml):
```yaml
name: Deploy to Railway

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Railway CLI
        run: npm i -g @railway/cli
      
      - name: Deploy to Railway
        run: railway up --service backend
        env:
          RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}
```

---

## å››ã€Vercelå‰ç«¯éƒ¨ç½²

### 4.1 Vercelé…ç½®

**vercel.json**:
```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "devCommand": "npm run dev",
  "installCommand": "npm install",
  "framework": "vite",
  "rewrites": [
    {
      "source": "/api/:path*",
      "destination": "https://automoney-backend.railway.app/api/:path*"
    }
  ]
}
```

### 4.2 ç¯å¢ƒå˜é‡

åœ¨Vercel Dashboardè®¾ç½®ï¼š
```
VITE_API_URL=https://automoney-backend.railway.app
VITE_WS_URL=wss://automoney-backend.railway.app
VITE_GOOGLE_CLIENT_ID=...
```

### 4.3 éƒ¨ç½²æ­¥éª¤

1. è¿æ¥GitHubä»“åº“
2. é€‰æ‹© `frontend` ç›®å½•
3. é…ç½®ç¯å¢ƒå˜é‡
4. ç‚¹å‡»Deploy

**è‡ªåŠ¨éƒ¨ç½²**: æ¨é€åˆ°mainåˆ†æ”¯è‡ªåŠ¨è§¦å‘

---

## äº”ã€æ•°æ®åº“ç®¡ç†

### 5.1 è¿ç§»ç®¡ç†ï¼ˆAlembicï¼‰

**åˆå§‹åŒ–**:
```bash
cd backend
alembic init alembic
```

**alembic/env.py** (é…ç½®):
```python
from app.models import Base
from app.core.config import settings

target_metadata = Base.metadata
config.set_main_option("sqlalchemy.url", settings.DATABASE_URL)
```

**åˆ›å»ºè¿ç§»**:
```bash
# è‡ªåŠ¨ç”Ÿæˆè¿ç§»
alembic revision --autogenerate -m "create users table"

# æ‰§è¡Œè¿ç§»
alembic upgrade head

# å›æ»š
alembic downgrade -1
```

### 5.2 æ•°æ®åº“å¤‡ä»½

**è‡ªåŠ¨å¤‡ä»½è„šæœ¬** (scripts/backup-db.sh):
```bash
#!/bin/bash

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="./backups"
BACKUP_FILE="$BACKUP_DIR/automoney_$DATE.sql"

mkdir -p $BACKUP_DIR

# å¤‡ä»½PostgreSQL
docker-compose exec -T postgres pg_dump -U automoney automoney_dev > $BACKUP_FILE

# å‹ç¼©
gzip $BACKUP_FILE

# åˆ é™¤30å¤©å‰çš„å¤‡ä»½
find $BACKUP_DIR -name "*.gz" -mtime +30 -delete

echo "âœ… å¤‡ä»½å®Œæˆ: ${BACKUP_FILE}.gz"
```

**å®šæ—¶ä»»åŠ¡** (crontab):
```bash
# æ¯å¤©å‡Œæ™¨3ç‚¹å¤‡ä»½
0 3 * * * /path/to/backup-db.sh
```

### 5.3 æ•°æ®åº“ä¼˜åŒ–

**å®šæœŸVACUUM** (PostgreSQL):
```sql
-- è‡ªåŠ¨VACUUMï¼ˆåœ¨postgresql.confä¸­é…ç½®ï¼‰
autovacuum = on
autovacuum_max_workers = 3

-- æ‰‹åŠ¨VACUUM
VACUUM ANALYZE trades;
VACUUM ANALYZE market_data;
```

**ç´¢å¼•ç»´æŠ¤**:
```sql
-- æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY schemaname, tablename;

-- é‡å»ºç´¢å¼•
REINDEX INDEX idx_trades_user_timestamp;
```

---

## å…­ã€ç›‘æ§ä¸æ—¥å¿—

### 6.1 æ—¥å¿—ç®¡ç†

**Logurué…ç½®** (app/core/logging.py):
```python
from loguru import logger
import sys

def setup_logging(environment: str):
    # ç§»é™¤é»˜è®¤handler
    logger.remove()
    
    # æ§åˆ¶å°è¾“å‡º
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
        level="INFO" if environment == "production" else "DEBUG"
    )
    
    # æ–‡ä»¶è¾“å‡ºï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    if environment == "production":
        logger.add(
            "logs/app_{time:YYYY-MM-DD}.log",
            rotation="1 day",
            retention="30 days",
            compression="gz",
            level="INFO"
        )
        
        # é”™è¯¯æ—¥å¿—å•ç‹¬å­˜å‚¨
        logger.add(
            "logs/errors_{time:YYYY-MM-DD}.log",
            rotation="1 day",
            retention="90 days",
            level="ERROR"
        )
```

### 6.2 Sentryé”™è¯¯è¿½è¸ª

**å®‰è£…**:
```bash
pip install sentry-sdk[fastapi]
```

**é…ç½®** (app/main.py):
```python
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

sentry_sdk.init(
    dsn="https://...@sentry.io/...",
    environment=settings.ENVIRONMENT,
    traces_sample_rate=0.1,  # é‡‡æ ·10%è¯·æ±‚
    profiles_sample_rate=0.1,
    integrations=[
        FastApiIntegration(),
    ],
)
```

**ä½¿ç”¨**:
```python
from sentry_sdk import capture_exception

try:
    result = await risky_operation()
except Exception as e:
    capture_exception(e)
    logger.error(f"Operation failed: {e}")
    raise
```

### 6.3 æ€§èƒ½ç›‘æ§

**Prometheus + Grafana**:

**å®‰è£…Prometheuså®¢æˆ·ç«¯**:
```bash
pip install prometheus-client
```

**é…ç½®æŒ‡æ ‡** (app/core/metrics.py):
```python
from prometheus_client import Counter, Histogram, Gauge

# è¯·æ±‚è®¡æ•°
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# å“åº”æ—¶é—´
http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

# Agentæ‰§è¡Œæ—¶é—´
agent_execution_seconds = Histogram(
    'agent_execution_seconds',
    'Agent execution duration',
    ['agent_type']
)

# LLM Tokenæ¶ˆè€—
llm_tokens_used = Counter(
    'llm_tokens_used_total',
    'Total LLM tokens used',
    ['model', 'agent_type']
)

# å½“å‰æ´»è·ƒç”¨æˆ·
active_users = Gauge(
    'active_users',
    'Number of active users'
)
```

**æš´éœ²æŒ‡æ ‡ç«¯ç‚¹**:
```python
from prometheus_client import make_asgi_app

# åœ¨main.pyä¸­
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

### 6.4 å¥åº·æ£€æŸ¥

**å¥åº·æ£€æŸ¥ç«¯ç‚¹** (app/api/v1/health.py):
```python
from fastapi import APIRouter, status
from sqlalchemy import text

router = APIRouter()

@router.get("/health")
async def health_check():
    """åŸºç¡€å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}

@router.get("/health/live")
async def liveness():
    """å­˜æ´»æ£€æŸ¥ï¼ˆK8s liveness probeï¼‰"""
    return {"status": "alive"}

@router.get("/health/ready")
async def readiness(db: AsyncSession = Depends(get_db)):
    """å°±ç»ªæ£€æŸ¥ï¼ˆK8s readiness probeï¼‰"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        await db.execute(text("SELECT 1"))
        
        # æ£€æŸ¥Redisè¿æ¥
        await redis_client.ping()
        
        return {
            "status": "ready",
            "database": "connected",
            "redis": "connected"
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"Service not ready: {str(e)}"
        )
```

---

## ä¸ƒã€å®‰å…¨åŠ å›º

### 7.1 HTTPSé…ç½®

**Railway**: è‡ªåŠ¨æä¾›HTTPSï¼Œæ— éœ€é…ç½®

**è‡ªå»ºNginx**:
```nginx
server {
    listen 80;
    server_name api.automoney.app;
    
    # é‡å®šå‘åˆ°HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name api.automoney.app;
    
    # SSLè¯ä¹¦ï¼ˆLet's Encryptï¼‰
    ssl_certificate /etc/letsencrypt/live/api.automoney.app/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/api.automoney.app/privkey.pem;
    
    # SSLé…ç½®
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;
    
    location / {
        proxy_pass http://backend:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### 7.2 CORSé…ç½®

**app/main.py**:
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://automoney.app",
        "https://www.automoney.app",
        "http://localhost:5173"  # å¼€å‘ç¯å¢ƒ
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### 7.3 é€Ÿç‡é™åˆ¶

**ä½¿ç”¨slowapi**:
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.get("/api/v1/agents/scores")
@limiter.limit("60/hour")
async def get_agent_scores(request: Request):
    pass
```

---

## å…«ã€æ•…éšœå¤„ç†

### 8.1 å¸¸è§é—®é¢˜æ’æŸ¥

**é—®é¢˜1: æ•°æ®åº“è¿æ¥å¤±è´¥**

```bash
# æ£€æŸ¥è¿æ¥
docker-compose exec backend python -c "
from app.core.database import engine
print('Database connected!' if engine else 'Failed')
"

# æ£€æŸ¥PostgreSQLæ—¥å¿—
docker-compose logs postgres
```

**é—®é¢˜2: Redisè¿æ¥è¶…æ—¶**

```bash
# æµ‹è¯•Redisè¿æ¥
docker-compose exec redis redis-cli ping

# æ¸…ç†Redisç¼“å­˜
docker-compose exec redis redis-cli FLUSHDB
```

**é—®é¢˜3: LLM APIè¶…æ—¶**

```bash
# æ£€æŸ¥API Key
curl -H "x-api-key: $CLAUDE_API_KEY" https://api.anthropic.com/v1/messages

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/errors_*.log | grep "LLM"
```

### 8.2 åº”æ€¥é¢„æ¡ˆ

**æ•°æ®åº“æ•…éšœ**:
1. ç«‹å³åˆ‡æ¢åˆ°åªè¯»æ¨¡å¼
2. ä»æœ€è¿‘å¤‡ä»½æ¢å¤
3. é€šçŸ¥ç”¨æˆ·ç»´æŠ¤ä¸­

**LLM APIæ•…éšœ**:
1. è‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨æ¨¡å‹
2. ä½¿ç”¨ç¼“å­˜çš„ä¸Šæ¬¡ç»“æœ
3. æš‚åœè‡ªåŠ¨ç­–ç•¥æ‰§è¡Œ

**æœåŠ¡å™¨å®•æœº**:
1. Railwayè‡ªåŠ¨é‡å¯ï¼ˆ5åˆ†é’Ÿå†…ï¼‰
2. æ£€æŸ¥å¥åº·æ£€æŸ¥æ—¥å¿—
3. å¿…è¦æ—¶å›æ»šåˆ°ä¸Šä¸ªç‰ˆæœ¬

---

## ä¹ã€æˆæœ¬ç›‘æ§

### 9.1 ç›‘æ§è„šæœ¬

**scripts/cost-monitor.py**:
```python
import asyncio
from datetime import datetime, timedelta
from app.core.database import get_db
from sqlalchemy import text

async def generate_cost_report():
    """ç”Ÿæˆæˆæœ¬æŠ¥å‘Š"""
    async with get_db() as db:
        # LLM Tokenæ¶ˆè€—
        result = await db.execute(text("""
            SELECT 
                agent_type,
                COUNT(*) as executions,
                SUM(tokens_used) as total_tokens,
                SUM(cost) as total_cost
            FROM agent_execution_logs
            WHERE created_at > NOW() - INTERVAL '30 days'
            GROUP BY agent_type
        """))
        
        print("ğŸ“Š LLMæˆæœ¬ç»Ÿè®¡ï¼ˆè¿‘30å¤©ï¼‰:")
        for row in result:
            print(f"  {row.agent_type}: ${row.total_cost:.2f} ({row.total_tokens:,} tokens)")
        
        # æ•°æ®æºAPIè°ƒç”¨
        result = await db.execute(text("""
            SELECT 
                data_source,
                COUNT(*) as calls
            FROM data_collection_logs
            WHERE created_at > NOW() - INTERVAL '30 days'
            GROUP BY data_source
        """))
        
        print("\nğŸ“¡ æ•°æ®æºAPIè°ƒç”¨:")
        for row in result:
            print(f"  {row.data_source}: {row.calls:,} æ¬¡")

if __name__ == "__main__":
    asyncio.run(generate_cost_report())
```

### 9.2 å‘Šè­¦è§„åˆ™

**é…ç½®å‘Šè­¦** (ä½¿ç”¨Railway CLI):
```bash
# æ¯æ—¥æˆæœ¬è¶…è¿‡$10å‘Šè­¦
railway alerts create \
  --name "High Daily Cost" \
  --metric "cost" \
  --threshold 10 \
  --period "1d"

# CPUä½¿ç”¨ç‡è¶…è¿‡80%å‘Šè­¦
railway alerts create \
  --name "High CPU" \
  --metric "cpu" \
  --threshold 80 \
  --period "5m"
```

---

## åã€è¿ç»´æ£€æŸ¥æ¸…å•

### 10.1 æ¯æ—¥æ£€æŸ¥

- [ ] æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼ˆSentry Dashboardï¼‰
- [ ] æ£€æŸ¥LLMæˆæœ¬ï¼ˆä¸è¶…è¿‡é¢„ç®—ï¼‰
- [ ] æŸ¥çœ‹APIå“åº”æ—¶é—´ï¼ˆP95 < 500msï¼‰
- [ ] æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± ï¼ˆæ— æ³„æ¼ï¼‰

### 10.2 æ¯å‘¨æ£€æŸ¥

- [ ] æ•°æ®åº“å¤‡ä»½éªŒè¯ï¼ˆæ¢å¤æµ‹è¯•ï¼‰
- [ ] æ¸…ç†è¿‡æœŸæ—¥å¿—å’Œç¼“å­˜
- [ ] æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡ï¼ˆ<80%ï¼‰
- [ ] æ›´æ–°ä¾èµ–åŒ…ï¼ˆå®‰å…¨è¡¥ä¸ï¼‰

### 10.3 æ¯æœˆæ£€æŸ¥

- [ ] æˆæœ¬ä¼˜åŒ–åˆ†æï¼ˆLLM/æ•°æ®æº/æœåŠ¡å™¨ï¼‰
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆæ…¢æŸ¥è¯¢åˆ†æï¼‰
- [ ] å®‰å…¨å®¡è®¡ï¼ˆä¾èµ–æ¼æ´æ‰«æï¼‰
- [ ] å¤‡ä»½æ¢å¤æ¼”ç»ƒ

---

**ğŸ“Œ å…³é”®Takeaway**: 
- Railwayéƒ¨ç½²ç®€å•ï¼Œé€‚åˆåˆæœŸ
- å®Œå–„çš„ç›‘æ§å’Œæ—¥å¿—ä½“ç³»
- è‡ªåŠ¨å¤‡ä»½å’Œæ•…éšœæ¢å¤
- æˆæœ¬å®æ—¶ç›‘æ§å’Œå‘Šè­¦

**ä¸‹ä¸€æ­¥**: æŒ‰ç…§æœ¬æ–‡æ¡£é…ç½®éƒ¨ç½²ç¯å¢ƒï¼Œå‡†å¤‡ä¸Šçº¿ï¼ğŸš€


