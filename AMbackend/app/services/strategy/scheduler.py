"""Strategy Scheduler - ç­–ç•¥è°ƒåº¦å™¨

å®šæ—¶ä»»åŠ¡:
1. ç­–ç•¥æ‰§è¡Œ Job (ç‹¬ç«‹å‘¨æœŸ,æ¯ä¸ªç­–ç•¥å¯é…ç½®)
2. å¸‚åœºæ•°æ®é‡‡é›† Job (æ¯30ç§’)
3. ç»„åˆå¿«ç…§ Job (æ¯å¤©0ç‚¹)
"""

import asyncio
import logging
from datetime import datetime
from typing import Optional
from decimal import Decimal

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy import select
from sqlalchemy.orm import selectinload

from app.core.config import settings
from app.models import User, Portfolio, PortfolioSnapshot
from app.services.strategy.strategy_orchestrator import strategy_orchestrator
from app.services.trading.portfolio_service import portfolio_service
from app.services.market.real_market_data import real_market_data_service
from app.services.strategy.real_agent_executor import real_agent_executor
from app.services.indicators.calculator import IndicatorCalculator
from app.services.data_collectors.manager import data_manager

logger = logging.getLogger(__name__)


class StrategyScheduler:
    """
    ç­–ç•¥è°ƒåº¦å™¨

    ç®¡ç†æ‰€æœ‰å®šæ—¶ä»»åŠ¡,æ”¯æŒæ¯ä¸ªç­–ç•¥ç‹¬ç«‹å‘¨æœŸ
    """

    def __init__(self):
        self.scheduler = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self.engine = None
        self.SessionLocal = None

    def _run_async_job(self, coro_func, *args, **kwargs):
        """åœ¨æ–°äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°(ç”¨äºBackgroundScheduler)

        CRITICAL: ä¸ºæ–°äº‹ä»¶å¾ªç¯åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯å·¥å‚,é¿å…AsyncPGè¿æ¥ç»‘å®šåˆ°æ—§äº‹ä»¶å¾ªç¯
        """
        logger.info(f"[Scheduler] _run_async_job called: {coro_func.__name__}")
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                # ğŸ”§ ä¸ºæ–°äº‹ä»¶å¾ªç¯åˆ›å»ºæ–°çš„æ•°æ®åº“å¼•æ“å’Œä¼šè¯å·¥å‚
                # AsyncPGè¿æ¥å¿…é¡»åœ¨åˆ›å»ºå®ƒä»¬çš„äº‹ä»¶å¾ªç¯ä¸­ä½¿ç”¨
                from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
                from app.core.config import settings

                temp_engine = create_async_engine(
                    settings.DATABASE_URL,
                    echo=False,
                    pool_pre_ping=True,
                )

                temp_session_factory = async_sessionmaker(
                    temp_engine,
                    expire_on_commit=False,
                    autocommit=False,
                    autoflush=False,
                )

                # ä¸´æ—¶æ›¿æ¢SessionLocal,è®©è°ƒåº¦ä»»åŠ¡ä½¿ç”¨æ–°çš„ä¼šè¯å·¥å‚
                original_session_local = self.SessionLocal
                self.SessionLocal = temp_session_factory

                try:
                    result = loop.run_until_complete(coro_func(*args, **kwargs))
                    logger.info(f"[Scheduler] _run_async_job completed: {coro_func.__name__}")
                    return result
                finally:
                    # æ¢å¤åŸå§‹SessionLocal
                    self.SessionLocal = original_session_local
                    # å…³é—­ä¸´æ—¶å¼•æ“
                    loop.run_until_complete(temp_engine.dispose())
            finally:
                loop.close()
        except Exception as e:
            logger.error(f"[Scheduler] _run_async_job error in {coro_func.__name__}: {e}", exc_info=True)
            raise

    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œè°ƒåº¦å™¨"""
        # åˆ›å»ºè°ƒåº¦å™¨ï¼ˆä½¿ç”¨åå°çº¿ç¨‹ï¼‰
        if self.scheduler is None:
            self.scheduler = BackgroundScheduler(timezone="UTC")

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self.engine = create_async_engine(
            settings.DATABASE_URL,
            echo=False,
            pool_pre_ping=True,
        )

        self.SessionLocal = async_sessionmaker(
            self.engine,
            expire_on_commit=False,
            autocommit=False,
            autoflush=False,
        )

        logger.info("ç­–ç•¥è°ƒåº¦å™¨æ•°æ®åº“è¿æ¥å·²åˆå§‹åŒ–")

    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        logger.info("[Scheduler] å¼€å§‹å¯åŠ¨è°ƒåº¦å™¨...")
        await self.initialize()
        logger.info("[Scheduler] è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")

        # æ·»åŠ å…¨å±€å®šæ—¶ä»»åŠ¡
        logger.info("[Scheduler] æ·»åŠ å…¨å±€å®šæ—¶ä»»åŠ¡...")
        self._add_global_jobs()

        # ä¸ºæ‰€æœ‰æ´»è·ƒç­–ç•¥æ·»åŠ ç‹¬ç«‹ä»»åŠ¡
        logger.info("[Scheduler] æ·»åŠ ç­–ç•¥å®šæ—¶ä»»åŠ¡...")
        await self._add_all_portfolio_jobs()

        # å¯åŠ¨è°ƒåº¦å™¨
        logger.info("[Scheduler] å¯åŠ¨è°ƒåº¦å™¨çº¿ç¨‹...")
        self.scheduler.start()
        logger.info("[Scheduler] âœ“ ç­–ç•¥è°ƒåº¦å™¨å·²å¯åŠ¨(BackgroundScheduler)")

        # æ‰“å°æ‰€æœ‰å·²æ³¨å†Œçš„ä»»åŠ¡åŠå…¶ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        jobs = self.scheduler.get_jobs()
        logger.info(f"[Scheduler] å·²æ³¨å†Œ {len(jobs)} ä¸ªä»»åŠ¡:")
        for job in jobs:
            logger.info(f"[Scheduler]   - {job.id}: {job.name}")
            logger.info(f"[Scheduler]     ä¸‹æ¬¡æ‰§è¡Œ: {job.next_run_time}")
            logger.info(f"[Scheduler]     è§¦å‘å™¨: {job.trigger}")

    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.scheduler.shutdown()
        logger.info("ç­–ç•¥è°ƒåº¦å™¨å·²åœæ­¢")

    def _add_global_jobs(self):
        """æ·»åŠ å…¨å±€å®šæ—¶ä»»åŠ¡"""

        # Job 1: å¸‚åœºæ•°æ®é‡‡é›† (æ¯30ç§’)
        self.scheduler.add_job(
            lambda: self._run_async_job(self.collect_market_data_job),
            trigger=IntervalTrigger(seconds=30),
            id="market_data_collection",
            name="å¸‚åœºæ•°æ®é‡‡é›†",
            replace_existing=True,
            max_instances=1,
        )

        # Job 3: ç»„åˆå¿«ç…§ (æ¯10åˆ†é’Ÿ)
        self.scheduler.add_job(
            lambda: self._run_async_job(self.create_portfolio_snapshots_job),
            trigger=IntervalTrigger(minutes=10),
            id="portfolio_snapshots",
            name="ç»„åˆå¿«ç…§",
            replace_existing=True,
            max_instances=1,
        )

        logger.info("å…¨å±€å®šæ—¶ä»»åŠ¡å·²æ·»åŠ ï¼ˆå¸‚åœºæ•°æ®+ç»„åˆå¿«ç…§ï¼‰")

    async def _add_all_portfolio_jobs(self):
        """
        ä¸ºæ¯ä¸ªç­–ç•¥æ¨¡æ¿æ·»åŠ ç‹¬ç«‹çš„æ‰¹é‡æ‰§è¡Œä»»åŠ¡

        ä¼˜åŒ–è¯´æ˜ï¼š
        - æŒ‰strategy_definition_idåˆ†ç»„
        - æ¯ä¸ªæ¨¡æ¿åˆ›å»ºä¸€ä¸ªå®šæ—¶ä»»åŠ¡ï¼Œä½¿ç”¨æ¨¡æ¿çš„rebalance_period_minutes
        - åŒä¸€æ¨¡æ¿çš„æ‰€æœ‰å®ä¾‹å…±äº«Agentåˆ†æç»“æœ
        """
        try:
            print(f"[Scheduler] å¼€å§‹æ·»åŠ ç­–ç•¥æ¨¡æ¿æ‰¹é‡æ‰§è¡Œä»»åŠ¡...")

            async with self.SessionLocal() as db:
                # 1. è·å–æ‰€æœ‰æ´»è·ƒçš„PortfolioåŠå…¶strategy_definition
                result = await db.execute(
                    select(Portfolio)
                    .options(selectinload(Portfolio.strategy_definition))
                    .where(Portfolio.is_active == True)
                )
                portfolios = result.scalars().all()

                if not portfolios:
                    logger.info("æ²¡æœ‰æ´»è·ƒçš„ç­–ç•¥å®ä¾‹")
                    return

                # 2. æŒ‰strategy_definition_idåˆ†ç»„
                from collections import defaultdict
                from app.models.strategy_definition import StrategyDefinition

                portfolios_by_definition = defaultdict(list)
                for portfolio in portfolios:
                    if portfolio.strategy_definition_id:
                        portfolios_by_definition[portfolio.strategy_definition_id].append(portfolio)

                logger.info(
                    f"æ‰¾åˆ° {len(portfolios)} ä¸ªæ´»è·ƒå®ä¾‹ï¼Œ"
                    f"åˆ†ä¸º {len(portfolios_by_definition)} ä¸ªç­–ç•¥æ¨¡æ¿ç»„"
                )

                # 3. ä¸ºæ¯ä¸ªæ¨¡æ¿ç»„åˆ›å»ºå®šæ—¶ä»»åŠ¡
                for definition_id, group_portfolios in portfolios_by_definition.items():
                    definition = group_portfolios[0].strategy_definition
                    if not definition:
                        logger.warning(f"ç­–ç•¥æ¨¡æ¿ {definition_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                        continue

                    # ä»æ¨¡æ¿è·å–æ‰§è¡Œå‘¨æœŸ
                    period_minutes = definition.default_params.get("rebalance_period_minutes", 10)

                    # åˆ›å»ºå®šæ—¶ä»»åŠ¡(ä½¿ç”¨åŒ…è£…å™¨è¿è¡Œå¼‚æ­¥å‡½æ•°)
                    job_id = f"strategy_template_{definition_id}"
                    logger.info(f"[Scheduler] æ­£åœ¨æ·»åŠ ä»»åŠ¡: {job_id}, å‘¨æœŸ={period_minutes}åˆ†é’Ÿ")
                    self.scheduler.add_job(
                        lambda def_id=definition_id: self._run_async_job(self.batch_execute_by_template, def_id),
                        trigger=IntervalTrigger(minutes=period_minutes),
                        id=job_id,
                        name=f"ç­–ç•¥æ¨¡æ¿æ‰§è¡Œ: {definition.display_name}",
                        replace_existing=True,
                        max_instances=1,
                    )
                    logger.info(f"[Scheduler] ä»»åŠ¡å·²æ·»åŠ : {job_id}")

                    logger.info(
                        f"âœ“ æ·»åŠ æ¨¡æ¿ä»»åŠ¡: {definition.display_name} "
                        f"(ID={definition_id}, å‘¨æœŸ={period_minutes}åˆ†é’Ÿ, å®ä¾‹æ•°={len(group_portfolios)})"
                    )
                    print(
                        f"[Scheduler] âœ“ {definition.display_name}: "
                        f"{period_minutes}åˆ†é’Ÿå‘¨æœŸ, {len(group_portfolios)}ä¸ªå®ä¾‹å…±äº«Agentåˆ†æ"
                    )

        except Exception as e:
            logger.error(f"æ·»åŠ ç­–ç•¥æ¨¡æ¿ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            print(f"[Scheduler] âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {e}")

    def add_portfolio_job(
        self, portfolio_id: str, portfolio_name: str, period_minutes: int
    ):
        """
        ä¸ºå•ä¸ªç­–ç•¥æ·»åŠ ç‹¬ç«‹çš„å®šæ—¶ä»»åŠ¡

        Args:
            portfolio_id: ç­–ç•¥ID
            portfolio_name: ç­–ç•¥åç§°
            period_minutes: æ‰§è¡Œå‘¨æœŸ(åˆ†é’Ÿ)
        """
        job_id = f"portfolio_{portfolio_id}"

        try:
            # å¦‚æœä»»åŠ¡å·²å­˜åœ¨,å…ˆç§»é™¤
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)

            # æ·»åŠ æ–°ä»»åŠ¡
            self.scheduler.add_job(
                self.execute_single_portfolio,
                trigger=IntervalTrigger(minutes=period_minutes),
                id=job_id,
                name=f"ç­–ç•¥æ‰§è¡Œ: {portfolio_name}",
                args=[portfolio_id],
                replace_existing=True,
                max_instances=1,  # é˜²æ­¢å¹¶å‘æ‰§è¡Œ
            )

            logger.info(
                f"å·²æ·»åŠ ç­–ç•¥ä»»åŠ¡: {portfolio_name} (ID: {portfolio_id}, "
                f"å‘¨æœŸ: {period_minutes}åˆ†é’Ÿ)"
            )
            print(
                f"[Scheduler]   âœ“ æ·»åŠ ä»»åŠ¡: {portfolio_name} (å‘¨æœŸ: {period_minutes}åˆ†é’Ÿ)"
            )

        except Exception as e:
            logger.error(
                f"æ·»åŠ ç­–ç•¥ä»»åŠ¡å¤±è´¥: {portfolio_name} (ID: {portfolio_id}) - {e}",
                exc_info=True,
            )
            print(
                f"[Scheduler]   âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {portfolio_name} - {e}"
            )

    def remove_portfolio_job(self, portfolio_id: str):
        """
        ç§»é™¤ç­–ç•¥çš„å®šæ—¶ä»»åŠ¡

        Args:
            portfolio_id: ç­–ç•¥ID
        """
        job_id = f"portfolio_{portfolio_id}"

        try:
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)
                logger.info(f"å·²ç§»é™¤ç­–ç•¥ä»»åŠ¡: {portfolio_id}")
            else:
                logger.warning(f"ç­–ç•¥ä»»åŠ¡ä¸å­˜åœ¨: {portfolio_id}")

        except Exception as e:
            logger.error(f"ç§»é™¤ç­–ç•¥ä»»åŠ¡å¤±è´¥: {portfolio_id} - {e}", exc_info=True)

    def update_portfolio_job(
        self, portfolio_id: str, portfolio_name: str, period_minutes: int
    ):
        """
        æ›´æ–°ç­–ç•¥çš„å®šæ—¶ä»»åŠ¡å‘¨æœŸ

        Args:
            portfolio_id: ç­–ç•¥ID
            portfolio_name: ç­–ç•¥åç§°
            period_minutes: æ–°çš„æ‰§è¡Œå‘¨æœŸ(åˆ†é’Ÿ)
        """
        logger.info(
            f"æ›´æ–°ç­–ç•¥ä»»åŠ¡: {portfolio_name} (ID: {portfolio_id}, "
            f"æ–°å‘¨æœŸ: {period_minutes}åˆ†é’Ÿ)"
        )

        # ç§»é™¤æ—§ä»»åŠ¡å¹¶æ·»åŠ æ–°ä»»åŠ¡
        self.remove_portfolio_job(portfolio_id)
        self.add_portfolio_job(portfolio_id, portfolio_name, period_minutes)

    async def execute_single_portfolio(self, portfolio_id: str):
        """
        æ‰§è¡Œå•ä¸ªç­–ç•¥

        Args:
            portfolio_id: ç­–ç•¥ID
        """
        logger.info(f"å¼€å§‹æ‰§è¡Œç­–ç•¥: {portfolio_id}")

        try:
            async with self.SessionLocal() as db:
                # 1. è·å–æŠ•èµ„ç»„åˆ
                result = await db.execute(
                    select(Portfolio).where(
                        Portfolio.id == portfolio_id, Portfolio.is_active == True
                    )
                )
                portfolio = result.scalar_one_or_none()

                if not portfolio:
                    logger.warning(f"ç­–ç•¥ä¸å­˜åœ¨æˆ–å·²åœç”¨: {portfolio_id}")
                    # ç§»é™¤ä»»åŠ¡
                    self.remove_portfolio_job(portfolio_id)
                    return

                # 2. é‡‡é›†å¸‚åœºæ•°æ®
                market_data = await self._fetch_market_data()

                # 3. æ‰§è¡Œç­–ç•¥
                try:
                    logger.info(
                        f"ä¸ºç»„åˆæ‰§è¡Œç­–ç•¥: {portfolio.name} (ID: {portfolio.id})"
                    )

                    # æ‰§è¡Œç­–ç•¥ï¼ˆè®© orchestrator è‡ªå·±æ‰§è¡Œ agents å¹¶è®°å½•ï¼‰
                    execution = await strategy_orchestrator.execute_strategy(
                        db=db,
                        user_id=portfolio.user_id,
                        portfolio_id=str(portfolio.id),
                        market_data=market_data,
                        agent_outputs=None,  # è®© orchestrator è‡ªå·±æ‰§è¡Œ agents
                    )

                    # 4. æ›´æ–° last_execution_time
                    portfolio.last_execution_time = datetime.utcnow()
                    await db.commit()

                    logger.info(
                        f"ç­–ç•¥æ‰§è¡Œå®Œæˆ - ç»„åˆ: {portfolio.name}, "
                        f"ä¿¡å·: {execution.signal}, "
                        f"çŠ¶æ€: {execution.status}"
                    )

                except Exception as e:
                    logger.error(
                        f"ç»„åˆç­–ç•¥æ‰§è¡Œå¤±è´¥: {portfolio.name} - {e}", exc_info=True
                    )

        except Exception as e:
            logger.error(f"ç­–ç•¥æ‰§è¡Œ Job å¤±è´¥: {portfolio_id} - {e}", exc_info=True)

    async def batch_execute_by_template(self, definition_id: int):
        """
        æŒ‰ç­–ç•¥æ¨¡æ¿æ‰¹é‡æ‰§è¡Œ - æ–°çš„æŒ‰æ¨¡æ¿åˆ†ç»„æ‰§è¡Œæ–¹æ³•

        å·¥ä½œæµç¨‹:
        1. è·å–æŒ‡å®šæ¨¡æ¿çš„æ‰€æœ‰æ´»è·ƒå®ä¾‹
        2. æ‰§è¡Œä¸€æ¬¡Agentåˆ†æï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
        3. ä¸ºæ¯ä¸ªå®ä¾‹æ‰§è¡Œå†³ç­–å’Œäº¤æ˜“

        Args:
            definition_id: ç­–ç•¥æ¨¡æ¿ID

        æˆæœ¬ä¼˜åŒ–:
        - åŒä¸€æ¨¡æ¿çš„æ‰€æœ‰å®ä¾‹å…±äº«Agentåˆ†æç»“æœ
        - LLMè°ƒç”¨æ¬¡æ•°: 1æ¬¡/å‘¨æœŸï¼ˆæ— è®ºæœ‰å¤šå°‘å®ä¾‹ï¼‰
        """
        logger.info(f"[Scheduler] Executing strategy template {definition_id}")
        try:
            async with self.SessionLocal() as db:
                # 1. è·å–æŒ‡å®šæ¨¡æ¿çš„æ‰€æœ‰æ´»è·ƒPortfolio
                result = await db.execute(
                    select(Portfolio)
                    .options(
                        selectinload(Portfolio.holdings),
                        selectinload(Portfolio.strategy_definition)
                    )
                    .where(
                        Portfolio.strategy_definition_id == definition_id,
                        Portfolio.is_active == True
                    )
                )
                portfolios = result.scalars().all()

                if not portfolios:
                    logger.info(f"ç­–ç•¥æ¨¡æ¿ {definition_id} æ²¡æœ‰æ´»è·ƒå®ä¾‹ï¼Œè·³è¿‡æ‰§è¡Œ")
                    return

                definition = portfolios[0].strategy_definition
                if not definition:
                    logger.error(f"ç­–ç•¥æ¨¡æ¿ {definition_id} ä¸å­˜åœ¨")
                    return

                logger.info(
                    f"\n{'='*60}\n"
                    f"æ‰§è¡Œç­–ç•¥æ¨¡æ¿: {definition.display_name} (ID={definition_id})\n"
                    f"å®ä¾‹æ•°: {len(portfolios)}\n"
                    f"ä¸šåŠ¡Agent: {definition.business_agents}\n"
                    f"{'='*60}"
                )

                # 2. ç”Ÿæˆæ‰¹æ¬¡IDï¼ˆç”¨äºå…³è”æœ¬æ¬¡æ‰¹é‡æ‰§è¡Œçš„æ‰€æœ‰è®°å½•ï¼‰
                import uuid
                batch_id = uuid.uuid4()
                logger.info(f"æ‰¹æ¬¡ID: {batch_id}")

            # 3. é‡‡é›†å¸‚åœºæ•°æ®(withé”™è¯¯è¿½è¸ª)
            try:
                market_data = await self._fetch_market_data()
            except Exception as e:
                logger.error(f"å¸‚åœºæ•°æ®é‡‡é›†å¤±è´¥: {e}")
                # è®°å½•é”™è¯¯åˆ°æ•°æ®åº“
                from app.services.monitoring.error_tracker import error_tracker
                await error_tracker.track_exception(
                    db=db,
                    exception=e,
                    error_type="data_collection",
                    component="Scheduler._fetch_market_data",
                    severity="critical",
                    context={
                        "definition_id": definition_id,
                        "definition_name": definition.name,
                        "portfolio_count": len(portfolios),
                    }
                )
                # ç»§ç»­æŠ›å‡ºå¼‚å¸¸,è®©ä¸Šå±‚å¤„ç†
                raise

            # 4. æ ¹æ®ç­–ç•¥å®šä¹‰åŠ¨æ€æ‰§è¡ŒAgentåˆ†æï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
            logger.info(f"æ‰§è¡ŒAgentåˆ†æï¼ˆ{len(portfolios)} ä¸ªå®ä¾‹å…±äº«ï¼‰")

            # ğŸ†• æ ¹æ®ç­–ç•¥å®šä¹‰é€‰æ‹©Agentæ‰§è¡Œå™¨
            # ğŸ”§ åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯ç”¨äºAgentæ‰§è¡Œï¼ˆé¿å…äº‹ä»¶å¾ªç¯å†²çªï¼‰
            async with self.SessionLocal() as agent_db:
                if definition.business_agents:
                    # ä½¿ç”¨åŠ¨æ€Agentæ‰§è¡Œå™¨(æ–°ç­–ç•¥)
                    from app.services.strategy.dynamic_agent_executor import dynamic_agent_executor

                    logger.info(f"ä½¿ç”¨åŠ¨æ€Agentæ‰§è¡Œå™¨: {definition.business_agents}")
                    agent_outputs, agent_errors = await dynamic_agent_executor.execute_agents(
                        agent_names=definition.business_agents,  # âœ… ä»ç­–ç•¥å®šä¹‰è¯»å–
                        market_data=market_data,
                        db=agent_db,  # âœ… ä½¿ç”¨æ–°çš„æ•°æ®åº“ä¼šè¯
                        user_id=portfolios[0].user_id,
                        strategy_execution_id=None,
                        template_execution_batch_id=batch_id,
                    )
                    logger.info(f"âœ… åŠ¨æ€Agentæ‰§è¡Œå®Œæˆ: {list(agent_outputs.keys())}")
                else:
                    # ä½¿ç”¨é»˜è®¤Agentæ‰§è¡Œå™¨(æ—§ç­–ç•¥,å‘åå…¼å®¹)
                    from app.services.strategy.real_agent_executor import RealAgentExecutor
                    agent_executor = RealAgentExecutor()

                    logger.info("ä½¿ç”¨é»˜è®¤Agentæ‰§è¡Œå™¨(æ—§ç­–ç•¥)")
                    agent_outputs, agent_errors = await agent_executor.execute_all_agents(
                        market_data=market_data,
                        db=agent_db,  # âœ… ä½¿ç”¨æ–°çš„æ•°æ®åº“ä¼šè¯
                        user_id=portfolios[0].user_id,
                        strategy_execution_id=None,
                        template_execution_batch_id=batch_id,
                    )
                    logger.info(f"âœ… é»˜è®¤Agentæ‰§è¡Œå®Œæˆ")

            # 5. ä¸ºæ¯ä¸ªPortfolioæ‰§è¡Œå†³ç­–å’Œäº¤æ˜“
            success_count = 0
            failure_count = 0

            async with self.SessionLocal() as db:
                for portfolio in portfolios:
                    try:
                        logger.info(
                            f"æ‰§è¡Œå®ä¾‹: {portfolio.instance_name} (ID: {portfolio.id})"
                        )

                        # ä½¿ç”¨å…±äº«çš„agent_outputsæ‰§è¡Œç­–ç•¥
                        execution = await strategy_orchestrator.execute_strategy(
                            db=db,
                            user_id=portfolio.user_id,
                            portfolio_id=str(portfolio.id),
                            market_data=market_data,
                            agent_outputs=agent_outputs,  # å…±äº«çš„åˆ†æç»“æœ
                            template_execution_batch_id=batch_id,  # ğŸ†• ä¼ é€’æ‰¹æ¬¡ID
                        )

                        # æ›´æ–°æ‰§è¡Œæ—¶é—´
                        portfolio.last_execution_time = datetime.utcnow()
                        await db.commit()

                        success_count += 1
                        logger.info(
                            f"âœ… å®ä¾‹æ‰§è¡Œå®Œæˆ - {portfolio.instance_name}, "
                            f"ä¿¡å·: {execution.signal}, çŠ¶æ€: {execution.status}"
                        )

                    except Exception as e:
                        failure_count += 1
                        logger.error(
                            f"âŒ å®ä¾‹æ‰§è¡Œå¤±è´¥: {portfolio.instance_name} - {e}",
                            exc_info=True
                        )

                        # è®°å½•é”™è¯¯
                        from app.services.monitoring.error_tracker import error_tracker
                        await error_tracker.track_exception(
                            db=db,
                            exception=e,
                            error_type="strategy_execution",
                            component="Scheduler.batch_execute_by_template",
                            severity="error",
                            context={
                                "portfolio_id": str(portfolio.id),
                                "portfolio_name": portfolio.instance_name,
                                "strategy_name": definition.name,
                            },
                            user_id=portfolio.user_id,
                            portfolio_id=str(portfolio.id),
                            strategy_name=definition.name,
                        )
                        # âš ï¸ é‡è¦ï¼šä¸è¦rollbackï¼
                        # strategy_orchestratorçš„å¼‚å¸¸å¤„ç†å·²ç»æ›´æ–°äº†executionçŠ¶æ€å¹¶commitäº†
                        # å¦‚æœè¿™é‡Œrollbackï¼Œä¼šå›æ»šexecutionçš„çŠ¶æ€æ›´æ–°ï¼Œå¯¼è‡´è®°å½•å¡åœ¨RUNNINGçŠ¶æ€
                        # åªéœ€è¦åˆ·æ–°sessionçŠ¶æ€ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå®ä¾‹
                        await db.refresh(portfolio) if portfolio else None
                        # ç»§ç»­ä¸‹ä¸€ä¸ªå®ä¾‹

            logger.info(
                f"\n{'='*60}\n"
                f"æ¨¡æ¿ {definition.display_name} æ‰§è¡Œå®Œæˆ:\n"
                f"  - æˆåŠŸ: {success_count}\n"
                f"  - å¤±è´¥: {failure_count}\n"
                f"  - Agentè°ƒç”¨: 1æ¬¡ï¼ˆèŠ‚çœ {len(portfolios) - 1} æ¬¡ï¼‰\n"
                f"{'='*60}"
            )

        except Exception as e:
            logger.error(f"æ¨¡æ¿ {definition_id} æ‰¹é‡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

    async def collect_market_data_job(self):
        """
        å¸‚åœºæ•°æ®é‡‡é›† Job

        å®šæœŸæ›´æ–°æ‰€æœ‰ç»„åˆçš„å¸‚åœºä»·å€¼
        """
        logger.info("å¼€å§‹é‡‡é›†å¸‚åœºæ•°æ®")

        try:
            async with self.SessionLocal() as db:
                # 1. é‡‡é›†å¸‚åœºæ•°æ®
                market_data = await self._fetch_market_data()

                btc_price = Decimal(str(market_data.get("btc_price", 0)))
                if btc_price == 0:
                    logger.warning("BTC ä»·æ ¼ä¸º 0ï¼Œè·³è¿‡ç»„åˆä»·å€¼æ›´æ–°")
                    return

                # 2. è·å–æ‰€æœ‰æ´»è·ƒç»„åˆ (with eager loading)
                result = await db.execute(
                    select(Portfolio)
                    .options(selectinload(Portfolio.holdings))
                    .where(Portfolio.is_active == True)
                )
                portfolios = result.scalars().all()

                # 3. æ›´æ–°ç»„åˆä»·å€¼
                for portfolio in portfolios:
                    try:
                        await portfolio_service.update_portfolio_value(
                            db=db,
                            portfolio=portfolio,
                            current_btc_price=btc_price,
                        )

                    except Exception as e:
                        logger.error(f"æ›´æ–°ç»„åˆä»·å€¼å¤±è´¥: {portfolio.name} - {e}")

                logger.info(
                    f"å¸‚åœºæ•°æ®é‡‡é›†å®Œæˆ - BTC: ${btc_price}, "
                    f"æ›´æ–°äº† {len(portfolios)} ä¸ªç»„åˆ"
                )

        except Exception as e:
            logger.error(f"å¸‚åœºæ•°æ®é‡‡é›† Job å¤±è´¥: {e}", exc_info=True)

    async def create_portfolio_snapshots_job(self):
        """
        ç»„åˆå¿«ç…§ Job

        æ¯å¤©åˆ›å»ºæ‰€æœ‰ç»„åˆçš„å¿«ç…§
        """
        logger.info("å¼€å§‹åˆ›å»ºç»„åˆå¿«ç…§")

        try:
            async with self.SessionLocal() as db:
                # 1. é‡‡é›†å¸‚åœºæ•°æ®
                market_data = await self._fetch_market_data()

                btc_price = Decimal(str(market_data.get("btc_price", 0)))
                snapshot_time = datetime.utcnow()

                # 2. è·å–æ‰€æœ‰æ´»è·ƒç»„åˆ (with eager loading)
                result = await db.execute(
                    select(Portfolio)
                    .options(selectinload(Portfolio.holdings))
                    .where(Portfolio.is_active == True)
                )
                portfolios = result.scalars().all()

                # 3. ä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºå¿«ç…§
                for portfolio in portfolios:
                    try:
                        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¿«ç…§,è®¡ç®—å¹¶ä¿å­˜ initial_btc_amount
                        if portfolio.initial_btc_amount is None and btc_price > 0:
                            portfolio.initial_btc_amount = portfolio.initial_balance / btc_price
                            logger.info(
                                f"åˆå§‹åŒ– BTC åŸºå‡†: {portfolio.name}, "
                                f"åˆå§‹ä½™é¢: ${portfolio.initial_balance}, "
                                f"BTC ä»·æ ¼: ${btc_price}, "
                                f"BTC æ•°é‡: {portfolio.initial_btc_amount}"
                            )

                        # è®¡ç®—æŒä»“ä»·å€¼
                        holdings_value = Decimal("0")
                        holdings_data = {}

                        for holding in portfolio.holdings:
                            holdings_value += holding.market_value
                            holdings_data[holding.symbol] = {
                                "amount": float(holding.amount),
                                "avg_buy_price": float(holding.avg_buy_price),
                                "current_price": float(holding.current_price),
                                "market_value": float(holding.market_value),
                                "unrealized_pnl": float(holding.unrealized_pnl),
                            }

                        # åˆ›å»ºå¿«ç…§
                        snapshot = PortfolioSnapshot(
                            portfolio_id=portfolio.id,
                            snapshot_time=snapshot_time,
                            total_value=portfolio.total_value,
                            balance=portfolio.current_balance,
                            holdings_value=holdings_value,
                            total_pnl=portfolio.total_pnl,
                            total_pnl_percent=portfolio.total_pnl_percent,
                            btc_price=btc_price,
                            holdings=holdings_data,
                        )

                        db.add(snapshot)

                        logger.info(
                            f"åˆ›å»ºç»„åˆå¿«ç…§: {portfolio.name}, "
                            f"æ€»ä»·å€¼: ${portfolio.total_value}"
                        )

                    except Exception as e:
                        logger.error(f"åˆ›å»ºç»„åˆå¿«ç…§å¤±è´¥: {portfolio.name} - {e}")

                await db.commit()

                logger.info(f"ç»„åˆå¿«ç…§åˆ›å»ºå®Œæˆ - å…± {len(portfolios)} ä¸ªç»„åˆ")

        except Exception as e:
            logger.error(f"ç»„åˆå¿«ç…§ Job å¤±è´¥: {e}", exc_info=True)

    async def reload_template_schedule(self, definition_id: int):
        """
        åŠ¨æ€é‡æ–°åŠ è½½æŒ‡å®šç­–ç•¥æ¨¡æ¿çš„è°ƒåº¦ä»»åŠ¡

        å½“adminä¿®æ”¹ç­–ç•¥æ¨¡æ¿çš„æ‰§è¡Œå‘¨æœŸæ—¶è°ƒç”¨æ­¤æ–¹æ³•ï¼Œç«‹å³ç”Ÿæ•ˆ

        Args:
            definition_id: ç­–ç•¥æ¨¡æ¿ID
        """
        try:
            logger.info(f"[Scheduler] å¼€å§‹é‡æ–°åŠ è½½ç­–ç•¥æ¨¡æ¿ {definition_id} çš„è°ƒåº¦ä»»åŠ¡")

            # 1. ç§»é™¤æ—§çš„è°ƒåº¦ä»»åŠ¡
            job_id = f"strategy_template_{definition_id}"
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)
                logger.info(f"[Scheduler] å·²ç§»é™¤æ—§ä»»åŠ¡: {job_id}")

            # 2. ä»æ•°æ®åº“é‡æ–°è¯»å–æœ€æ–°é…ç½®
            async with self.SessionLocal() as db:
                from app.models.strategy_definition import StrategyDefinition

                result = await db.execute(
                    select(StrategyDefinition).where(
                        StrategyDefinition.id == definition_id
                    )
                )
                definition = result.scalar_one_or_none()

                if not definition:
                    logger.warning(f"[Scheduler] ç­–ç•¥æ¨¡æ¿ {definition_id} ä¸å­˜åœ¨")
                    return

                # 3. è·å–ä½¿ç”¨æ­¤æ¨¡æ¿çš„æ‰€æœ‰æ¿€æ´»å®ä¾‹
                result = await db.execute(
                    select(Portfolio).where(
                        Portfolio.strategy_definition_id == definition_id,
                        Portfolio.is_active == True
                    )
                )
                portfolios = result.scalars().all()

            # 4. å¦‚æœæ²¡æœ‰æ¿€æ´»å®ä¾‹ï¼Œä¸åˆ›å»ºä»»åŠ¡
            if not portfolios:
                logger.info(
                    f"[Scheduler] ç­–ç•¥æ¨¡æ¿ '{definition.display_name}' "
                    f"æ— æ¿€æ´»å®ä¾‹ï¼Œä¸åˆ›å»ºè°ƒåº¦ä»»åŠ¡"
                )
                return

            # 5. è¯»å–æœ€æ–°çš„æ‰§è¡Œå‘¨æœŸé…ç½®
            period_minutes = definition.default_params.get("rebalance_period_minutes", 10)

            # 6. åˆ›å»ºæ–°çš„è°ƒåº¦ä»»åŠ¡
            self.scheduler.add_job(
                self.batch_execute_by_template,
                trigger=IntervalTrigger(minutes=period_minutes),
                id=job_id,
                name=f"ç­–ç•¥æ¨¡æ¿æ‰§è¡Œ: {definition.display_name}",
                args=[definition_id],
                replace_existing=True,
                max_instances=1,
            )

            logger.info(
                f"[Scheduler] âœ“ é‡æ–°åŠ è½½å®Œæˆ: {definition.display_name} "
                f"(ID={definition_id}, æ–°å‘¨æœŸ={period_minutes}åˆ†é’Ÿ, å®ä¾‹æ•°={len(portfolios)})"
            )

        except Exception as e:
            logger.error(f"[Scheduler] é‡æ–°åŠ è½½ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            raise

    async def _fetch_market_data(self) -> dict:
        """
        é‡‡é›†çœŸå®å¸‚åœºæ•°æ®å¹¶è½¬æ¢ä¸ºAgentæœŸæœ›çš„æ ¼å¼

        ä½¿ç”¨çœŸå®çš„å¸‚åœºæ•°æ® APIï¼ˆCoinGecko, Binance, Alternative.me, FREDï¼‰

        è¿”å›æ ¼å¼:
        {
            "assets": {
                "BTC": {
                    "current_price": 43250.0,
                    "price_change_24h": 3.5,
                    "ohlcv_15m": [...],
                    "ohlcv_60m": [...],
                    "funding_rate": 0.0001,
                    "open_interest_change_24h": 5.2,
                    "futures_premium": 0.5,
                    ...
                },
                "ETH": {...},
                "SOL": {...}
            },
            "macro": {
                "dxy": 103.5,
                "fed_rate": 3.87,
                ...
            },
            "sentiment": {
                "fear_greed_value": 65,
                ...
            },
            "onchain": {
                "btc_mvrv_zscore": 2.5
            }
        }
        """
        try:
            logger.info("ğŸ“Š å¼€å§‹é‡‡é›†å¸‚åœºæ•°æ®...")

            # 1. è·å–åŸå§‹å¸‚åœºæ•°æ®
            raw_snapshot = await real_market_data_service.get_complete_market_snapshot()
            logger.info(f"âœ… åŸå§‹æ•°æ®é‡‡é›†æˆåŠŸ: BTC ${raw_snapshot['btc_price']:.2f}")

            # 2. æ”¶é›† OHLCV æ•°æ®
            all_data = await data_manager.collect_all()
            logger.info("âœ… OHLCVæ•°æ®é‡‡é›†å®Œæˆ")

            # 3. è½¬æ¢ä¸ºAgentæœŸæœ›çš„æ ¼å¼
            logger.info("ğŸ”„ å¼€å§‹è½¬æ¢æ•°æ®æ ¼å¼...")

            # 3.1 æ„å»º assets ç»“æ„
            assets = {}

            # BTC æ•°æ®
            btc_asset = {
                "current_price": float(raw_snapshot["btc_price"]),
                "price_change_24h": raw_snapshot["btc_price_change_24h"],
                "volume_24h": raw_snapshot.get("btc_volume_24h", 0),
            }

            # æ·»åŠ  OHLCV Kçº¿æ•°æ®
            if hasattr(all_data, "btc_ohlcv") and all_data.btc_ohlcv:
                # 15åˆ†é’ŸKçº¿ (æœ€è¿‘100æ ¹)
                btc_asset["ohlcv_15m"] = all_data.btc_ohlcv[-100:] if len(all_data.btc_ohlcv) > 100 else all_data.btc_ohlcv
                # 60åˆ†é’ŸKçº¿ (ä»15åˆ†é’Ÿèšåˆ,å–æ¯4æ ¹)
                btc_asset["ohlcv_60m"] = all_data.btc_ohlcv[-400::4] if len(all_data.btc_ohlcv) > 400 else all_data.btc_ohlcv[::4]
                logger.info(f"  âœ… BTC Kçº¿æ•°æ®: 15m={len(btc_asset['ohlcv_15m'])}æ ¹, 60m={len(btc_asset['ohlcv_60m'])}æ ¹")
            else:
                logger.warning("  âš ï¸  BTC OHLCVæ•°æ®ç¼ºå¤±,ä½¿ç”¨ç©ºæ•°ç»„")
                btc_asset["ohlcv_15m"] = []
                btc_asset["ohlcv_60m"] = []

            # æ·»åŠ è¡ç”Ÿå“æ•°æ® (TODO: ä»çœŸå®APIè·å–,æš‚æ—¶ä½¿ç”¨åˆç†çš„æ¨¡æ‹Ÿå€¼)
            btc_asset["funding_rate"] = 0.0001  # 0.01% - å…¸å‹çš„æ­£å¸¸èµ„é‡‘è´¹ç‡
            btc_asset["open_interest_change_24h"] = 2.5  # 2.5% - æ¸©å’Œå¢é•¿
            btc_asset["futures_premium"] = 0.3  # 0.3% - å¥åº·çš„æœŸè´§æº¢ä»·
            logger.info(f"  ğŸ“ˆ BTCè¡ç”Ÿå“æ•°æ®(Mock): funding={btc_asset['funding_rate']:.4f}, OI_change={btc_asset['open_interest_change_24h']:.1f}%")

            assets["BTC"] = btc_asset

            # ETH æ•°æ®
            if raw_snapshot.get("eth_price"):
                eth_asset = {
                    "current_price": float(raw_snapshot["eth_price"]),
                    "price_change_24h": raw_snapshot.get("eth_price_change_24h", 0),
                    "volume_24h": 0,
                    "ohlcv_15m": [],  # TODO: æ·»åŠ ETH Kçº¿
                    "ohlcv_60m": [],
                    "funding_rate": 0.0001,
                    "open_interest_change_24h": 2.0,
                    "futures_premium": 0.25,
                }
                assets["ETH"] = eth_asset
                logger.info(f"  âœ… ETHæ•°æ®: ${eth_asset['current_price']:.2f}")
            else:
                logger.warning("  âš ï¸  ETHæ•°æ®ç¼ºå¤±")

            # SOL æ•°æ® (TODO: æ·»åŠ SOLæ•°æ®é‡‡é›†)
            assets["SOL"] = {
                "current_price": 100.0,  # Mock
                "price_change_24h": 1.5,
                "volume_24h": 0,
                "ohlcv_15m": [],
                "ohlcv_60m": [],
                "funding_rate": 0.00015,
                "open_interest_change_24h": 3.0,
                "futures_premium": 0.4,
            }
            logger.info("  âš ï¸  SOLæ•°æ®ä½¿ç”¨Mockå€¼")

            # 3.2 æ„å»º macro ç»“æ„ (é‡å‘½åå­—æ®µä»¥åŒ¹é…agentæœŸæœ›)
            macro = {
                "dxy": raw_snapshot["macro"].get("dxy_index", 103.0),
                "fed_rate": raw_snapshot["macro"].get("fed_funds_rate", 5.5),
                "m2_growth": raw_snapshot["macro"].get("m2_growth", 2.5),
                "treasury_10y": raw_snapshot["macro"].get("treasury_10y", 4.5),
                "vix": raw_snapshot["macro"].get("vix", 15.0),
            }
            logger.info(f"  ğŸ“Š å®è§‚æ•°æ®: DXY={macro['dxy']:.1f}, Fed={macro['fed_rate']:.2f}%")

            # 3.3 æ„å»º sentiment ç»“æ„ (é‡å‘½åå­—æ®µ)
            sentiment = {
                "fear_greed_value": raw_snapshot["fear_greed"].get("value", 50),
                "fear_greed_classification": raw_snapshot["fear_greed"].get("classification", "Neutral"),
            }
            logger.info(f"  ğŸ˜° æƒ…ç»ªæŒ‡æ ‡: Fear&Greed={sentiment['fear_greed_value']}")

            # 3.4 æ„å»º onchain ç»“æ„ (TODO: æ·»åŠ çœŸå®é“¾ä¸Šæ•°æ®)
            onchain = {
                "btc_mvrv_zscore": 1.8,  # Mock - MVRV Z-Score (1-3ä¸ºå¥åº·åŒºé—´)
            }
            logger.info(f"  â›“ï¸  é“¾ä¸Šæ•°æ®(Mock): MVRV={onchain['btc_mvrv_zscore']:.1f}")

            # 4. ç»„è£…æœ€ç»ˆæ•°æ®ç»“æ„
            market_data = {
                "assets": assets,
                "macro": macro,
                "sentiment": sentiment,
                "onchain": onchain,
                "timestamp": raw_snapshot.get("timestamp"),
                "last_updated": raw_snapshot.get("last_updated"),
            }

            logger.info(f"âœ… å¸‚åœºæ•°æ®æ ¼å¼è½¬æ¢å®Œæˆ - åŒ…å« {len(assets)} ä¸ªèµ„äº§")
            logger.info(f"   - BTC: ${assets['BTC']['current_price']:.2f} ({assets['BTC']['price_change_24h']:+.2f}%)")
            logger.info(f"   - Fear&Greed: {sentiment['fear_greed_value']}")
            logger.info(f"   - DXY: {macro['dxy']:.1f}, Fed Rate: {macro['fed_rate']:.2f}%")

            return market_data

        except Exception as e:
            logger.error(f"âŒ å¸‚åœºæ•°æ®é‡‡é›†å¤±è´¥: {e}", exc_info=True)
            raise  # å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ï¼Œä¸å†è¿”å›æ¨¡æ‹Ÿæ•°æ®


# å…¨å±€å®ä¾‹
strategy_scheduler = StrategyScheduler()
